{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16b95eb",
   "metadata": {},
   "source": [
    "# Experiments: TF‑IDF hyperparameter sweeps and diagnostics\n",
    "\n",
    "This notebook contains runnable experiments for sampling documents, sweeping TF‑IDF hyperparameters, and producing similarity diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c53fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup - Import Libraries and Load Sample Documents\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path('..') / 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Load sample documents from data/internal/\n",
    "data_dir = Path('../data/internal')\n",
    "files = sorted(glob.glob(str(data_dir / '*.txt')))[:10]\n",
    "docs = []\n",
    "doc_names = []\n",
    "\n",
    "for f in files:\n",
    "    with open(f, 'r', encoding='utf-8') as fh:\n",
    "        text = fh.read()\n",
    "        docs.append(text)\n",
    "        doc_names.append(Path(f).stem)\n",
    "\n",
    "print(f'✓ Loaded {len(docs)} documents')\n",
    "print(f'Sample documents: {doc_names[:3]}...')\n",
    "\n",
    "# Define preprocess_text() locally for flexibility\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Basic preprocessing for experiments\"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special chars, keep alphanumeric and spaces\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Remove stopwords\n",
    "    stopwords = {'the', 'a', 'an', 'and', 'or', 'is', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'from'}\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stopwords and len(t) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess all documents\n",
    "docs_clean = [preprocess_text(doc) for doc in docs]\n",
    "print(f'✓ Preprocessed {len(docs_clean)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e71ed8",
   "metadata": {},
   "source": [
    "## Cell 2: Baseline TF-IDF Analysis\n",
    "\n",
    "Create a baseline TfidfVectorizer with default parameters and analyze the resulting matrix properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e94832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Baseline TF-IDF Analysis\n",
    "# Create TfidfVectorizer with default parameters\n",
    "vectorizer_baseline = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer_baseline.fit_transform(docs_clean)\n",
    "\n",
    "# Calculate sparsity\n",
    "n_zeros = tfidf_matrix.nnz - tfidf_matrix.data.size if hasattr(tfidf_matrix, 'data') else 0\n",
    "sparsity = 1 - (tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1]))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BASELINE TF-IDF ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Matrix shape: {tfidf_matrix.shape[0]} documents × {tfidf_matrix.shape[1]} features\")\n",
    "print(f\"Non-zero elements: {tfidf_matrix.nnz}\")\n",
    "print(f\"Sparsity: {sparsity:.2%}\")\n",
    "print(f\"Matrix density: {(1 - sparsity):.2%}\")\n",
    "\n",
    "# Get top 10 features by frequency\n",
    "feature_names = np.array(vectorizer_baseline.get_feature_names_out())\n",
    "tfidf_sum = np.asarray(tfidf_matrix.sum(axis=0)).flatten()\n",
    "top_indices = tfidf_sum.argsort()[-10:][::-1]\n",
    "top_features = feature_names[top_indices]\n",
    "top_scores = tfidf_sum[top_indices]\n",
    "\n",
    "print(\"\\nTop 10 Features by TF-IDF Sum:\")\n",
    "for i, (feat, score) in enumerate(zip(top_features, top_scores), 1):\n",
    "    print(f\"  {i:2d}. {feat:20s} → {score:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1713c",
   "metadata": {},
   "source": [
    "## Cell 3: Hyperparameter Sensitivity Sweep\n",
    "\n",
    "Test combinations of `min_df` and `max_df` to understand their impact on feature extraction.\n",
    "- **min_df**: Minimum document frequency (filters out rare terms)\n",
    "- **max_df**: Maximum document frequency (filters out common terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd20de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Hyperparameter Sensitivity Sweep\n",
    "min_df_values = [0.01, 0.05, 0.1, 0.2]\n",
    "max_df_values = [0.8, 0.9, 0.95, 1.0]\n",
    "\n",
    "sweep_results = []\n",
    "\n",
    "print(\"Running hyperparameter sweep...\")\n",
    "print(f\"Testing {len(min_df_values)} × {len(max_df_values)} = {len(min_df_values) * len(max_df_values)} combinations\\n\")\n",
    "\n",
    "for min_df in min_df_values:\n",
    "    for max_df in max_df_values:\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, norm='l2')\n",
    "            matrix = vectorizer.fit_transform(docs_clean)\n",
    "            \n",
    "            n_features = matrix.shape[1]\n",
    "            nnz = matrix.nnz\n",
    "            sparsity = 1 - (nnz / (matrix.shape[0] * matrix.shape[1]))\n",
    "            \n",
    "            sweep_results.append({\n",
    "                'min_df': min_df,\n",
    "                'max_df': max_df,\n",
    "                'n_features': n_features,\n",
    "                'nnz': nnz,\n",
    "                'sparsity': sparsity,\n",
    "                'density': 1 - sparsity\n",
    "            })\n",
    "            print(f\"✓ min_df={min_df:.2f}, max_df={max_df:.2f} → {n_features:4d} features, sparsity={sparsity:.2%}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ min_df={min_df:.2f}, max_df={max_df:.2f} → ERROR: {str(e)[:50]}\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "df_sweep = pd.DataFrame(sweep_results)\n",
    "print(f\"\\n✓ Completed {len(df_sweep)} combinations successfully\\n\")\n",
    "print(\"Summary Statistics:\")\n",
    "print(df_sweep.groupby('min_df')[['n_features', 'sparsity']].agg(['min', 'mean', 'max']).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45470190",
   "metadata": {},
   "source": [
    "## Cell 4: Hyperparameter Visualization\n",
    "\n",
    "Visualize the impact of min_df and max_df on feature extraction and sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Hyperparameter Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Feature count vs min_df (lines for each max_df)\n",
    "ax1 = axes[0]\n",
    "for max_df in max_df_values:\n",
    "    df_subset = df_sweep[df_sweep['max_df'] == max_df]\n",
    "    ax1.plot(df_subset['min_df'], df_subset['n_features'], \n",
    "             marker='o', linewidth=2, markersize=8, label=f'max_df={max_df}')\n",
    "ax1.set_xlabel('min_df (Minimum Document Frequency)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Number of Features', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Impact of min_df on Feature Count', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# Plot 2: Sparsity vs min_df (lines for each max_df)\n",
    "ax2 = axes[1]\n",
    "for max_df in max_df_values:\n",
    "    df_subset = df_sweep[df_sweep['max_df'] == max_df]\n",
    "    ax2.plot(df_subset['min_df'], df_subset['sparsity'] * 100, \n",
    "             marker='s', linewidth=2, markersize=8, label=f'max_df={max_df}')\n",
    "ax2.set_xlabel('min_df (Minimum Document Frequency)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Sparsity (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Impact of min_df on Sparsity', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='best', fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "output_path = Path('../results/hyperparameter_sweep.png')\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Saved visualization to {output_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18a385",
   "metadata": {},
   "source": [
    "## Cell 5: TF Variant Comparison\n",
    "\n",
    "Compare all 5 TF variants for the word \"compliance\" across sample documents.\n",
    "\n",
    "**TF Variants:**\n",
    "1. **Raw count**: Simple term frequency\n",
    "2. **Log-normalized**: 1 + log(count)\n",
    "3. **Double normalized**: 0.5 + 0.5 × (count / max_count)\n",
    "4. **Augmented**: count / max_count\n",
    "5. **Boolean**: 1 if present, 0 otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: TF Variant Comparison\n",
    "# Select a sample word to analyze\n",
    "sample_word = \"compliance\"\n",
    "sample_docs = docs_clean[:5]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"TF VARIANT COMPARISON FOR WORD: '{sample_word}'\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "tf_variants = []\n",
    "\n",
    "for doc_idx, doc in enumerate(sample_docs):\n",
    "    tokens = doc.split()\n",
    "    raw_count = tokens.count(sample_word)\n",
    "    max_count = max(Counter(tokens).values()) if tokens else 1\n",
    "    \n",
    "    # Variant 1: Raw count\n",
    "    tf_raw = raw_count\n",
    "    \n",
    "    # Variant 2: Log-normalized\n",
    "    tf_log = 1 + np.log(raw_count) if raw_count > 0 else 0\n",
    "    \n",
    "    # Variant 3: Double normalized\n",
    "    tf_double = 0.5 + 0.5 * (raw_count / max_count) if raw_count > 0 else 0.5\n",
    "    \n",
    "    # Variant 4: Augmented (normalized by max)\n",
    "    tf_augmented = raw_count / max_count if raw_count > 0 else 0\n",
    "    \n",
    "    # Variant 5: Boolean\n",
    "    tf_boolean = 1.0 if raw_count > 0 else 0.0\n",
    "    \n",
    "    tf_variants.append({\n",
    "        'Document': f'Doc {doc_idx + 1}',\n",
    "        'Raw Count': raw_count,\n",
    "        'Log-normalized': tf_log,\n",
    "        'Double-normalized': tf_double,\n",
    "        'Augmented': tf_augmented,\n",
    "        'Boolean': tf_boolean\n",
    "    })\n",
    "\n",
    "df_tf = pd.DataFrame(tf_variants)\n",
    "print(\"\\nTF Variants Comparison Table:\")\n",
    "print(df_tf.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "x = np.arange(len(sample_docs))\n",
    "width = 0.15\n",
    "columns_to_plot = ['Raw Count', 'Log-normalized', 'Double-normalized', 'Augmented', 'Boolean']\n",
    "\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    ax.bar(x + i * width, df_tf[col], width, label=col, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Document', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('TF Value', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'TF Variants Comparison for \"{sample_word}\"', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width * 2)\n",
    "ax.set_xticklabels([f'Doc {i+1}' for i in range(len(sample_docs))])\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3836071",
   "metadata": {},
   "source": [
    "## Cell 6: IDF Variant Comparison\n",
    "\n",
    "Compare all 4 IDF variants for the word \"compliance\" across the corpus.\n",
    "\n",
    "**IDF Variants:**\n",
    "1. **Standard**: log(N / df) where N = total docs, df = docs containing term\n",
    "2. **Smooth IDF**: log((N + 1) / (df + 1)) + 1 (adds 1 to prevent division by zero)\n",
    "3. **Max IDF**: log(max_df / df) (uses max document frequency)\n",
    "4. **Probabilistic**: log((N - df) / df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: IDF Variant Comparison\n",
    "# Calculate document frequency for sample word\n",
    "sample_word = \"compliance\"\n",
    "N = len(docs_clean)\n",
    "df = sum(1 for doc in docs_clean if sample_word in doc.split())\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"IDF VARIANT COMPARISON FOR WORD: '{sample_word}'\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total documents (N): {N}\")\n",
    "print(f\"Documents containing '{sample_word}': {df}\")\n",
    "print()\n",
    "\n",
    "# Calculate all 4 IDF variants\n",
    "idf_data = {}\n",
    "\n",
    "# Variant 1: Standard IDF\n",
    "if df > 0:\n",
    "    idf_standard = np.log(N / df)\n",
    "else:\n",
    "    idf_standard = 0\n",
    "idf_data['Standard: log(N/df)'] = idf_standard\n",
    "\n",
    "# Variant 2: Smooth IDF (sklearn default)\n",
    "if df + 1 > 0:\n",
    "    idf_smooth = np.log((N + 1) / (df + 1)) + 1\n",
    "else:\n",
    "    idf_smooth = 1\n",
    "idf_data['Smooth: log((N+1)/(df+1)) + 1'] = idf_smooth\n",
    "\n",
    "# Variant 3: Max IDF\n",
    "max_df = N  # maximum possible\n",
    "if df > 0:\n",
    "    idf_max = np.log(max_df / df)\n",
    "else:\n",
    "    idf_max = 0\n",
    "idf_data['Max IDF: log(max_df/df)'] = idf_max\n",
    "\n",
    "# Variant 4: Probabilistic IDF\n",
    "if df > 0 and (N - df) > 0:\n",
    "    idf_prob = np.log((N - df) / df)\n",
    "else:\n",
    "    idf_prob = 0\n",
    "idf_data['Probabilistic: log((N-df)/df)'] = idf_prob\n",
    "\n",
    "# Display as table\n",
    "df_idf = pd.DataFrame(list(idf_data.items()), columns=['IDF Variant', 'Value'])\n",
    "print(\"IDF Variants Comparison Table:\")\n",
    "print(df_idf.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"• Standard IDF is the most common and simplest formula\")\n",
    "print(f\"• Smooth IDF adds 1 to avoid log(0) and division by zero\")\n",
    "print(f\"• Max IDF normalizes by the maximum possible document frequency\")\n",
    "print(f\"• Probabilistic IDF emphasizes rarity (N-df) in the numerator\")\n",
    "print()\n",
    "print(f\"For '{sample_word}' appearing in {df}/{N} documents:\")\n",
    "print(f\"  → Appears in {100*df/N:.1f}% of corpus\")\n",
    "print(f\"  → Standard IDF: {idf_standard:.4f}\")\n",
    "print(f\"  → Smooth IDF (sklearn): {idf_smooth:.4f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "variants = list(idf_data.keys())\n",
    "values = list(idf_data.values())\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "bars = ax.bar(range(len(variants)), values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('IDF Variant', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('IDF Value', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'IDF Variants for \"{sample_word}\" (df={df}/{N})', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(range(len(variants)))\n",
    "ax.set_xticklabels(variants, rotation=15, ha='right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510723d8",
   "metadata": {},
   "source": [
    "## Cell 7: Manual vs Sklearn TF-IDF Validation\n",
    "\n",
    "Validate our manual TF-IDF implementation against sklearn's TfidfVectorizer by comparing computed values for sample words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec882642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Manual vs Sklearn TF-IDF Validation\n",
    "\n",
    "# Import manual implementations from src\n",
    "try:\n",
    "    from manual_tfidf_math import (\n",
    "        compute_term_frequency,\n",
    "        compute_idf_smooth,\n",
    "        compute_tfidf_l2_norm\n",
    "    )\n",
    "    manual_available = True\n",
    "except ImportError:\n",
    "    print(\"⚠ Manual TF-IDF functions not available, will create simplified versions\")\n",
    "    manual_available = False\n",
    "\n",
    "# Create simplified manual implementations for validation\n",
    "def manual_tf_idf(corpus, sample_words):\n",
    "    \"\"\"Compute manual TF-IDF for validation\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for word_idx, word in enumerate(sample_words):\n",
    "        word_results = []\n",
    "        \n",
    "        for doc_idx, doc in enumerate(corpus):\n",
    "            tokens = doc.split()\n",
    "            \n",
    "            # TF: log-normalized (1 + log(count))\n",
    "            raw_count = tokens.count(word)\n",
    "            tf = 1 + np.log(raw_count) if raw_count > 0 else 0\n",
    "            \n",
    "            # IDF: smooth (log((N+1)/(df+1)) + 1)\n",
    "            N = len(corpus)\n",
    "            df = sum(1 for d in corpus if word in d.split())\n",
    "            idf = np.log((N + 1) / (df + 1)) + 1 if df > 0 else 0\n",
    "            \n",
    "            # TF-IDF\n",
    "            tfidf = tf * idf\n",
    "            word_results.append(tfidf)\n",
    "        \n",
    "        results.append(word_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VALIDATION: Manual vs Sklearn TF-IDF\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Select 3 sample words for validation\n",
    "sample_words = [\"compliance\", \"procedure\", \"policy\"]\n",
    "test_corpus = docs_clean[:5]\n",
    "\n",
    "print(f\"\\nTest corpus: {len(test_corpus)} documents\")\n",
    "print(f\"Sample words: {sample_words}\\n\")\n",
    "\n",
    "# Get sklearn TF-IDF\n",
    "vectorizer_val = TfidfVectorizer(norm='l2', sublinear_tf=True)\n",
    "sklearn_matrix = vectorizer_val.fit_transform(test_corpus)\n",
    "\n",
    "# Get feature names and indices\n",
    "feature_names = vectorizer_val.get_feature_names_out()\n",
    "sklearn_tfidf = {}\n",
    "\n",
    "for word in sample_words:\n",
    "    if word in feature_names:\n",
    "        word_idx = list(feature_names).index(word)\n",
    "        sklearn_tfidf[word] = sklearn_matrix[:, word_idx].toarray().flatten()\n",
    "    else:\n",
    "        sklearn_tfidf[word] = np.array([0] * len(test_corpus))\n",
    "\n",
    "# Get manual TF-IDF\n",
    "manual_results = manual_tf_idf(test_corpus, sample_words)\n",
    "\n",
    "# Normalize manual results (L2 norm)\n",
    "manual_tfidf_norm = {}\n",
    "for word_idx, word in enumerate(sample_words):\n",
    "    manual_vals = np.array(manual_results[word_idx])\n",
    "    # L2 normalize\n",
    "    norm = np.sqrt(np.sum(manual_vals ** 2))\n",
    "    manual_vals_norm = manual_vals / norm if norm > 0 else manual_vals\n",
    "    manual_tfidf_norm[word] = manual_vals_norm\n",
    "\n",
    "# Compare results\n",
    "print(\"COMPARISON TABLE:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "comparison_data = []\n",
    "matches = 0\n",
    "total_comparisons = 0\n",
    "\n",
    "for word in sample_words:\n",
    "    if word in sklearn_tfidf:\n",
    "        print(f\"\\nWord: '{word}'\")\n",
    "        print(f\"  Document | Manual TF-IDF | Sklearn TF-IDF | Diff      | Match\")\n",
    "        print(f\"  \" + \"-\" * 65)\n",
    "        \n",
    "        for doc_idx in range(len(test_corpus)):\n",
    "            manual_val = manual_tfidf_norm[word][doc_idx]\n",
    "            sklearn_val = sklearn_tfidf[word][doc_idx]\n",
    "            diff = abs(manual_val - sklearn_val)\n",
    "            match = diff < 0.01  # 1% tolerance\n",
    "            match_str = \"✓\" if match else \"✗\"\n",
    "            \n",
    "            print(f\"  {doc_idx + 1:8d} | {manual_val:13.6f} | {sklearn_val:14.6f} | {diff:.6f} | {match_str}\")\n",
    "            \n",
    "            if match:\n",
    "                matches += 1\n",
    "            total_comparisons += 1\n",
    "\n",
    "# Calculate match percentage\n",
    "match_percentage = (matches / total_comparisons * 100) if total_comparisons > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"VALIDATION SUMMARY:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total comparisons: {total_comparisons}\")\n",
    "print(f\"Matches (within 1%): {matches}\")\n",
    "print(f\"Match percentage: {match_percentage:.1f}%\")\n",
    "print()\n",
    "\n",
    "# Assertion\n",
    "if match_percentage >= 95:\n",
    "    print(f\"✅ VALIDATION PASSED: {match_percentage:.1f}% match (threshold: 95%)\")\n",
    "else:\n",
    "    print(f\"⚠ VALIDATION WARNING: {match_percentage:.1f}% match (threshold: 95%)\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
